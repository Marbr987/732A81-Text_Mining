# 732A81-Text_Mining
Previous studies have established that explanations produced by GPT-3 using few-shot prompts show high approval rates in a human evaluation. To further investigate the influence of using few-shot prompts with GPT-3 (fsp-GPT-3), free-text explanations were generated using a fsp-GPT-3 model and compared to explanations produced by a fine-tuned GPT-2 model (ft-GPT-2). The analysis includes calculating surface features like average number of words per explanations. Then, based on the core-structure of each explanation, phrase patterns were extracted using k-Medoids clustering and Na√Øve Bayes estimates for conditional probabilities to calculate importance weights for n-grams in the explanations. Lastly, human evaluation was performed on the explanations. Those analyses were performed on the fsp-GPT-3, the ft-GPT-2, and on a set of Gold explanations. The major findings are that explanations produced by fsp-GPT-3 are longer than the ones produced by ft-GPT-2 and that the proportion of explanations that follow a template-like structure is higher for fsp-GPT-3 explanations. Furthermore, the fine-tuned GPT-2 did not reveal more similar phrase patterns to the Gold explanations than the fsp-GPT-3 model. The human evaluation suggests that fsp-GPT-3 explanations have higher human approval rates and tend to contain novel information that was not part of its input more often.

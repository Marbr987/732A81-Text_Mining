{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Setup"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Packages"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import openai\n",
    "import re\n",
    "import time\n",
    "from scripts.prepare_data_helpers import prepare_examples, create_query\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepare Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "train1 = pd.read_csv('../../e-SNLI/dataset/esnli_train_1.csv')\n",
    "train2 = pd.read_csv('../../e-SNLI/dataset/esnli_train_2.csv')\n",
    "train = pd.concat([train1, train2])\n",
    "dev = pd.read_csv('../../e-SNLI/dataset/esnli_dev.csv')\n",
    "test = pd.read_csv('../../e-SNLI/dataset/esnli_test.csv')\n",
    "\n",
    "train = train.dropna(subset=['Sentence1', 'Sentence2', 'Explanation_1'])\n",
    "train = train.reset_index(drop=True)\n",
    "\n",
    "np.random.seed(12345) # seed for numpy package\n",
    "test_indices = list(np.random.choice(test.index.values, size=1000, replace=False))\n",
    "test = test.loc[test_indices]\n",
    "test = test.reset_index(drop=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "np.random.seed(12345) # seed for numpy package\n",
    "random.seed(12345) # seed for random package\n",
    "prompts = [prepare_examples(train, size_per_class=1, include_label=True) + '\\n\\n' + create_query(test.loc[i], include_label=True) for i in test.index]\n",
    "test['prompt'] = prompts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Generate Predictions on Test Set"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "pred_expl = list()\n",
    "pred_label = list()\n",
    "for i in range(int(np.ceil(test.shape[0] / 20))):\n",
    "    if i != 0:\n",
    "        time.sleep(60) # API allows only 20 calls or one call with 20 prompts per minute\n",
    "    indices = np.arange(i * 20, (i + 1) * 20)\n",
    "    response = openai.Completion.create(\n",
    "        engine='text-davinci-003',\n",
    "        prompt=list(test.iloc[indices].prompt),\n",
    "        temperature=0.5,\n",
    "        max_tokens=58,\n",
    "        top_p=1,\n",
    "    )\n",
    "    pred_expl += [re.findall('Explanation:.+', response.choices[i].text)[0].replace('Explanation: ', '').strip() for i in range(len(response.choices))]\n",
    "    pred_label += [re.findall('.+\\nExplanation:', response.choices[i].text)[0].replace('\\nExplanation:', '').replace('Label: ', '').strip() for i in range(len(response.choices))]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "test_output = test\n",
    "test_output['pred_explanation'] = pred_expl\n",
    "test_output['pred_label'] = pred_label\n",
    "test_output.to_csv('../output_data/test_predictions.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "test_output.to_csv('../output_data/test_predictions.csv', sep=';')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "0.675"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(test_output.gold_label == test_output.pred_label)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_label     assumption  contradiction  entailment  equivalence  equivalent  \\\n",
      "gold_label                                                                      \n",
      "contradiction           0            299           5            0           0   \n",
      "entailment              0              2         332            3           1   \n",
      "neutral                 1             73         146            1           1   \n",
      "\n",
      "pred_label     implication  inference  neutral  partial entailment  \\\n",
      "gold_label                                                           \n",
      "contradiction            0          0       27                   0   \n",
      "entailment               0          0       16                   1   \n",
      "neutral                  2          4       44                   0   \n",
      "\n",
      "pred_label     redundancy  reinforcement  repetition  speculation  synonym  \\\n",
      "gold_label                                                                   \n",
      "contradiction           0              0           0            1        0   \n",
      "entailment              1              1           1            1        3   \n",
      "neutral                 0              0           0           27        0   \n",
      "\n",
      "pred_label     tautology  unrelated  \n",
      "gold_label                           \n",
      "contradiction          0          4  \n",
      "entailment             3          0  \n",
      "neutral                0          0  \n"
     ]
    }
   ],
   "source": [
    "print(pd.crosstab(test_output.gold_label, test_output.pred_label))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}